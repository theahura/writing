<title>writing</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link rel="icon" href="spy.ico" type="image/x-icon" />
<link rel="shortcut icon" href="spy.ico" type="image/x-icon" />
<link rel="stylesheet" href="theme.css" />

<style></style>
<!-- Google Analytics -->
<script
  async
  src="https://www.googletagmanager.com/gtag/js?id=UA-131666667-1"
></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() {
    dataLayer.push(arguments);

    gtag("js", new Date());

    gtag("config", "UA-131666667-1");
</script>

<div class="header">
  <h1>Writing</h1>
  <h3>Amol Kapoor</h3>
</div>

<div class="content">
  <div class="writing-holder">
    <h4>Simple DL Part 1: Introduction</h4>

    <div class="writing">
      <p>
        Modern deep learning is a weird place. We have these amazing tools that
        are constantly redefining what can be done with computers (go take a
        look at
        <a
          href="https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology"
        >
          AlphaFold</a
        >), and yet we don't have any way of describing how these things
        actually work. Clearly <i>someone</i> knows what they are doing, because
        surely we aren't driving all those cars on a hunch? (*cough*) But from
        the outside looking in, it's witchcraft.
      </p>

      <div class="image-holder">
        <img src="witches.jpg" width="400" />
        <p>
          Yann LeCun, Geoffrey Hinton, Yoshua Bengio doing Deep Learning,
          probably.
        </p>
      </div>

      <p>
        Or, well, it was to me when I got started. After five years of actually
        working on this stuff, I think I've finally developed enough intuition
        to figure out how to actually do something interesting with this
        technology in a consistent way. Intuition is the cornerstone of modern
        Deep Learning practice.
      </p>
      <p>
        I think of ML scientists as the modern equivalent of Roman bridge builders.
        Humanity wouldn't figure out how to formalize bridge building until Newton
        came along...but the Romans still made some damn good bridges. The individual
        engineers all had these mental models of how bridge building worked, and that
        allowed them to innovate and optimize. Even though every model was wrong, 
        some of those models were useful. You even see the same kind of rise and
        fall of 'architectures'. For years everyone builds
        <a href="https://en.wikipedia.org/wiki/Clapper_bridge">Clapper bridges</a>,
        and then one day an engineer wakes up and goes 'Hey maybe
        <a href="https://en.wikipedia.org/wiki/Arch_bridge">arches</a> would be
        better' and everyone starts doing that. 
     </p>
     <p>
        The Newton of Deep Learning will show up eventually, but it might take
        a few hundred years. In the meantime, we have to make due with intuition.
        Luckily, I think it's possible to build a pretty good mental model of deep ML
        models through practice. Yea, the first few times a model fails, it'll be a
        frustrating experience. But eventually you should be able to pattern match
        and generalize, doing a human form of gradient descent. In that sense, Deep
        learning is a bit like sculpture or photography -- after a while, you get
        an eye for it.
     </p>
      <div class="image-holder">
        <img src="david.jpg" width="400" />
        <p>
          Michelangelo would've made a decent data scientist.
        </p>
      </div>
      <p>
        There are a lot of ML guides floating around out there, so let me start
        by saying what SimpleDL is <i>not</i>. It's not an implementation guide
        -- if I'm lucky I'll stay pretty far from actual code. It's not a dive
        into literature -- in a few places I might link to papers, and I might
        do a separate series on individual papers, but not here. It's not a
        highly rigorous mathematical approach to DL. It's not a history of ML.
        It's not a course on ML. It's definitely not a social commentary on ML.
      </p>
      <p>
        This series is, first and foremost, about building an intuition for deep
        learning. The goal is for the reader to come away with an instinct for
        sniffing out what a model is doing, and why, and how.
      </p>
      <p>
        Before diving in, I want to highlight a few resources that really helped
        me get off the ground. First, the
        <a
          href="https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/"
        >
          Oxford ML Class by Nando de Freitas</a
        >. If you're interested in doing an actual course on this stuff, I think
        it's hard to beat this class. Second, the
        <a href="https://www.youtube.com/user/ProfNandoDF">
          Deep Learning Youtube Videos</a
        >
        also by Nando de Freitas. Nando is an amazing lecturer, and I think he
        does an excellent job mixing theory and practice.
      </p>
      <p>
        Also, thanks for coming by to read some of the things I write! I hope
        it's useful/interesting. I don't know how frequently I'll update here,
        but when I do I'll post on <a href="https://twitter.com/theahura_">Twitter</a>.
      </p>
    </div>
  </div>

  <div class="writing-holder">
    <h4>Simple DL Part 2: Embeddings</h4>
    <div class="writing">
      <p>WIP</p>
      <p>
        Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod
        tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim
        veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea
        commodo consequat. Duis aute irure dolor in reprehenderit in voluptate
        velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint
        occaecat cupidatat non proident, sunt in culpa qui officia deserunt
        mollit anim id est laborum.
      </p>
    </div>
  </div>
</div>

<div class="footer"></div>
