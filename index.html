<title>writing</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link rel="icon" href="spy.ico" type="image/x-icon" />
<link rel="shortcut icon" href="spy.ico" type="image/x-icon" />
<link rel="stylesheet" href="theme.css" />

<style></style>
<!-- Google Analytics -->
<script
  async
  src="https://www.googletagmanager.com/gtag/js?id=UA-131666667-1"
></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() {
    dataLayer.push(arguments);
  }
  gtag("js", new Date());

  gtag("config", "UA-131666667-1");
</script>

<div class="header">
  <h1>Writing</h1>
  <h3>Amol Kapoor</h3>
</div>

<div class="content">
  <div class="writing-holder">
    <h4>Simple DL Part 1: Introduction</h4>

    <div class="writing">
      <p>
        Modern deep learning is a weird place. We have these amazing tools that
        are constantly redefining what can be done with computers (go take a
        look at
        <a
          href="https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology"
        >
          AlphaFold</a
        >), and yet we don't have any way of describing how these things
        actually work. Clearly <i>someone</i> knows what they are doing, because
        surely we aren't driving all those cars on a hunch? (*cough*) But from
        the outside looking in, it's witchcraft. Or, well, it was to me when I
        got started. 
      </p>

      <div class="image-holder">
        <img src="witches.jpg" width="400" />
        <p>
          Yann LeCun, Geoffrey Hinton, Yoshua Bengio doing Deep Learning,
          probably.
        </p>
      </div>

      <p>
        After five years of actually working on this stuff, I think I've finally
        developed enough intuition to figure out how to actually do something
        interesting with this technology in a consistent way. And one of the first
        things I learned is that intuition is the cornerstone of modern Deep
        Learning practice.
      </p>
      <p>
        I think of ML scientists as the modern equivalent of Roman bridge builders.
        Humanity wouldn't figure out how to formalize bridge building until Newton
        came along...but the Romans still made some damn good bridges. The individual
        engineers all had these mental models of how bridge building worked, and that
        allowed them to innovate and optimize. Even though every model was wrong, 
        some of those models were useful. You even see the same kind of rise and
        fall of 'architectures'. For years everyone builds
        <a href="https://en.wikipedia.org/wiki/Clapper_bridge">Clapper bridges</a>,
        and then one day an engineer wakes up and goes 'Hey maybe
        <a href="https://en.wikipedia.org/wiki/Arch_bridge">arches</a> would be
        better' and everyone starts doing that. 
     </p>
     <p>
        The Newton of Deep Learning will show up eventually, but it might take
        a few hundred years. In the meantime, we have to make due with intuition.
        Luckily, I think it's possible to build a pretty good mental model of deep ML
        models through practice. Yea, the first few times a model fails, it'll be a
        frustrating experience. But eventually you should be able to pattern match
        and generalize, doing a human form of gradient descent. In that sense, Deep
        learning is a bit like sculpture or photography -- after a while, you get
        an eye for it.
     </p>
      <div class="image-holder">
        <img src="david.jpg" width="400" />
        <p>
          Michelangelo would've made a decent data scientist.
        </p>
      </div>
      <p>
        There are a lot of ML guides floating around out there, so let me start
        by saying what SimpleDL is <i>not</i>. It's not an implementation guide
        -- if I'm lucky I'll stay pretty far from actual code. It's not a dive
        into literature -- in a few places I might link to papers, and I might
        do a separate series on individual papers, but not here. It's not a
        highly rigorous mathematical approach to DL. It's not a history of ML.
        It's not a course on ML. It's definitely not a social commentary on ML.
      </p>
      <p>
        This series is, first and foremost, about building an intuition for deep
        learning. The goal is for the reader to come away with an instinct for
        sniffing out what a model is doing, and why, and how.
      </p>
      <p>
        This series is titled SimpleDL because I want to make things simple. But
        some familiarity with basic computing concepts will be helpful. If you've
        never touched a computer before, this series probably isn't for you. I'll
        be aiming for 'intermediate programmer, never worked in ML before' as my
        audience.
      </p>
      <p>
        Before diving in, I want to highlight a few resources that really helped
        me get off the ground. First, the
        <a
          href="https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/"
        >
          Oxford ML Class by Nando de Freitas</a
        >. If you're interested in doing an actual course on this stuff, I think
        it's hard to beat this class. Second, the
        <a href="https://www.youtube.com/user/ProfNandoDF">
          Deep Learning Youtube Videos</a
        >
        also by Nando de Freitas. Nando is an amazing lecturer, and I think he
        does an excellent job mixing theory and practice.
      </p>
      <p>
        Also, thanks for coming by to read some of the things I write! I hope
        it's useful/interesting. I don't know how frequently I'll update here,
        but when I do I'll post on <a href="https://twitter.com/theahura_">Twitter</a>.
      </p>
    </div>
  </div>

  <div class="writing-holder">
    <h4>Simple DL Part 2: Embeddings</h4>
    
    <h6>WIP</h6>
    
    <div class="writing">
      <p>
        In my opinion, you cannot begin to understand Deep Learning without
        wrapping your brain around embeddings. Embeddings are the magic fairy dust
        that power every Deep Learning model, from ImageNet to GPT-3. All of my
        future posts in this series are going to refer back extensively to the
        embedding concept, so this is also going to be an important foundation for
        SimpleDL.
      </p>
      <h6>Embedding Basics</h6>
      <p>
        We'll start with a definition: an embedding is a list of numbers (a float
        vector) that represents some information. You can have embeddings for just
        about any kind of information out there. There are
        <a href="https://en.wikipedia.org/wiki/Word_embedding">word embeddings</a>.
        There are
        <a href="https://en.wikipedia.org/wiki/Sentence_embedding">sentence embeddings</a>.
        There are <a href="https://rom1504.medium.com/image-embeddings-ed1b194d113e">image
        embeddings</a>. There are
        <a href="https://en.wikipedia.org/wiki/Graph_embedding">graph embeddings</a>.
        There are
        <a href="https://www.cs.cornell.edu/~kb/publications/SIG15ProductNet.pdf">furniture embeddings</a>.
        Basically, if you can think of a concept, you can represent it as an embedding.
      </p>
      <h6>Information vs Format</h6>
      <p>
        This is already kinda weird. How can we take any concept and represent it as
        a list of numbers? To really grasp this idea, we need to remember that <b>
        information is not the format </b>. This is a core principle of
        <a href="https://en.wikipedia.org/wiki/Information_theory">information theory</a>
        and underpins most of modern computer science. Basically, we can take a piece
        of information and represent it in any format, and the underlying information
        won't be any different. Now, we might lose information in the conversion
        process, but that's due to practical limitations of the format of choice. 
      </p>
      <p>
        An example may help nail all this down. Let's say we have a picture of my
        wonderful dogs, Sparky and Lego.
      </p>
      <div class="image-holder">
        <img src="sparky_and_lego.jpeg" width="400" />
        <p>
          Dogs!
        </p>
      </div>
      <p>
        There is a lot of information in this picture. What if we wanted to convert
        that information to text? Can we perfectly represent the image? Well, we
        could describe the image. "Two dogs" captures most of the information in
        the image. "One small brown dog and one medium-sized gold dog on a slate
        grey surface" captures even more of the image. We can keep going
        like this, with ever more complex descriptions -- a picture is literally
        worth a thousand words.
      </p>
      <p>
        But why are we limiting ourselves to such a highly compressed representation?
        "Two dogs" captures a lot of the information, but its just 8 characters. It will
        always leave something out. What if we instead went pixel by pixel and wrote out
        the colors? Starting from the top left, we could write "grey, grey, grey, light
        grey, light grey, grey, grey...". Not exactly Hemingway, but it would be a
        perfect representation of the image. We would capture all of the information.
        Again, the information is not the format. There is nothing inherently 'image-like'
        about the information captured in the image above.
      </p>
      <p>
        Hopefully the leap to an embedding is straightforward. Instead of words,
        we could use RGB values and then flatten those out so that we get a
        single list -- something like [128, 128, 128, 128, 128, 128...]. We've turned
        our image into a numeric vector that perfectly captures all of the information
        in the original image.
      </p>
      <p>
        What about text? Can we turn text into an embedding? Well, one strategy could
        be to turn every letter into a numeric code, like ASCII. This is why a numeric
        sequence like 104 101 108 108 111 32 119 111 114 108 100 can be read as 'hello
        world' by a computer. If we had a really long sequence of text, like a book,
        we could instead turn every unique word into a number from 0 to N, where N is
        the number of unique words. Again, we've turned our data into a numeric vector
        that perfectly captures all of the original information.
      </p>
      <p>
        Ok so hopefully by now you have some intuition for what an embedding is. A
        question: is [0.124, 458.2356, 85.3, 2.01] an embedding? Or is it a random
        list of numbers? 
      </p>
      <p>
        Hopefully you see the problem with our initial definition.
      </p>
      <p>        
        An embedding is a list of numbers (a float vector) that represents some
        information, <em>as well as a mechanism for encoding and decoding that float
        vector to something useful</em>. In the examples above, our encoding/decoding
        scheme was RGB or ASCII. In Deep Learning, our encoder/decoder is the Deep
        ML model.
      </p>
      <h6>Format Matters</h6>
      <p>
        Some of you might be wondering why we bother with a float vector in the first
        place. After all, if we can perfectly capture information in a bunch of
        different ways, why float vectors? Humans have a really tough time reasoning
        about float vectors, surely there's an easier representation?
      </p>
      <p>
        The neat thing about float vectors is that they are continuous representations.
        You can <em>compare</em> them. You can <em>add them together</em>. You can
        <em>average</em> them. You can do all these neat mathematical operations on them
        that let you quickly and efficiently shift your data around. And this is really
        powerful, because you can turn concepts into computation.
      </p>
      <p>
        Let's say we wanted to represent two concepts: gender, and royal status. We can
        represent these two concepts as numbers in a vector of size 2. In other words,
        we can map any coordinate [X, Y] to a gender/royal status pairing. We can 
        arbitrarily assign +X to be more masculine, -X to be more feminine, +Y to be
        more royal, and -Y to be less royal. 
      </p>
      <div class="image-holder">
        <img src="sparky_and_lego.jpeg" width="400" />
        <p>
          Not a political compass meme.
        </p>
      </div>
      <p>
        With this rough coordinate system, we can <em>embed</em> words by mapping them
        into coordinates. For example, we might say the word King is mapped to 
        coordinates [1, 1]; the word Queen is mapped to [-1, 1]; the word Man is mapped
        to [1, 0], and the word Woman is mapped to [-1, 0].
      </p>
      <div class="image-holder">
        <img src="sparky_and_lego.jpeg" width="400" />
        <p>
          Not a political compass meme.
        </p>
      </div>
      <p>
        For a slightly different framing, I think float vectors are neat because they
        correspond really well to geography. People aren't great at remembering lots of
        numbers, but we are pretty good at spatial reasoning. Embeddings allow us
        to map concepts into geometric spaces. The technical term for this is a
        N-dimensional manifold. 
      </p>
      <h6>Imperfect Information</h6>
      <p>
        With infinite resources, we could perfectly convert any piece of data from one
        format to another. That's neat, but also just about useless. Most of the time,
        we care about _removing_ information, filtering important data from noise.
        This is especially true in Deep Learning. A
        <a href="https://www.youtube.com/watch?v=ACmydtFDTGs">hotdog image classifier</a>
        is taking in thousands of pixel values and returning only a single bit. 
      </p>
      <p>
        When we talk about embeddings, we generally refer to a float-vector that compresses
        the relevant information into a smaller, more manageable size while still keeping
        the important information around.
      </p>
    </div>
  </div>
</div>

<div class="footer"></div>
