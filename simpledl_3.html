<title>writing</title>
<meta name="viewport" content="width=800" />
<link rel="icon" href="spy.ico" type="image/x-icon" />
<link rel="shortcut icon" href="spy.ico" type="image/x-icon" />
<link rel="stylesheet" href="theme.css" />

<style></style>
<!-- Google Analytics -->
<script
  async
  src="https://www.googletagmanager.com/gtag/js?id=UA-131666667-1"
></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() {
    dataLayer.push(arguments);
  }
  gtag("js", new Date());

  gtag("config", "UA-131666667-1");
</script>

<div class="header">
  <h1>Writing</h1>
  <h3>Amol Kapoor</h3>
</div>

<div class="content">
  <div class="writing-holder">
    <h4>Simple DL Part 3: Losses and Features</h4>
    <h6>December, 2020</h6>

    <div class="writing">
      <h6>Recap</h6>
      <p>
        In the <a href="./simple2l_2.html">last section</a> we talked
        extensively about embeddings: what they are, how they worked, and why
        they are important. An embedding as a list of floats that carries some
        information about a concept; because embeddings are continuous
        representations, they can turn concepts into computation. A set of
        embeddings can be thought of as points on a map, that somehow represents
        the underlying 'important' structure of the things we are learning
        about. Loss functions and features are used to manipulate embeddings in
        a deep neural network -- in this section, we look at these in more
        depth.
      </p>
      <h6>TLDR</h6>
      <ul>
        <li>
          Features are the baseline input data to our model. Loss functions are
          how we tell the model what information to emphasize or to throw away.
        </li>
        <li>
          When thinking about losses, we care about three things: what the model
          produces, what we are comparing against, and how we do the comparison.
        </li>
        <li>
          Models will cheat if they can. We need to be careful about our data as
          a result.
        </li>
        <li>
          Losses can be placed on any embedding -- they do not just have to be
          at the end. The closer a loss is to an embedding, the more influence
          it will have.
        </li>
      </ul>
      <h6>Definitions</h6>
      <p>
        A deep neural network takes in some piece of data represented as an
        embedding (i.e. a list of numbers). It passes the data through a stack
        of transformations, each of which produces an intermediate embedding.
        And then the model outputs some final embedding, depending on what the
        task is.
      </p>
      <div class="image-holder">
        <img src="img/turtles.jpg" width="400" />
        <p>
          It's embeddings all the way down.
        </p>
      </div>
      <p>
        During training, we want to quantify how good that final output is -- we
        do this with a loss function. In practice, the loss function takes the
        output of the DNN and produces a single number. The DNN tries to
        minimize that number. We're not gonna dive into <i>how</i> the model
        minimizes the loss, because I think in practice it's rarely relevant for
        understanding DNNs. But if you're interested take a look at the wiki
        page for
        <a href="https://en.wikipedia.org/wiki/Backpropagation">backprop</a>.
      </p>
      <p>
        If we want to try and put this into a single sentence, a loss function
        is a function f(x) or f(x, y) that measures how well the model output x
        matches a specific piece of information, possibly defined by some
        external source y. When thinking about a whole training set, the loss
        function is a measure of how well the model output matches a certain
        distribution.
      </p>
      <div class="image-holder">
        <img src="img/loss-distribution.png" width="600" />
        <p>
          For most tasks, the loss is defined as some kind of distance between
          two distributions -- the model output and some external truth
          distribution -- that quantifies the model's performance.
        </p>
      </div>
      <p>
        Features are a bit easier to define -- the features are the input data.
        For a given input, we generally have multiple features describing that
        input. If we input an image, we could include the pixel data, the GPS
        metadata, camera parameters, and more. Each one of these would be a
        single feature.
      </p>
      <h6>Models Cheat</h6>
      <p>
        Part of what makes models hard to reason about is that models will
        'cheat' if they can. If a model has an easy way to minimize the loss, it
        will take it. Let's say we wanted to train a model to identify cats and
        dogs. If we only feed in images of cats during training, our model will
        never figure out how to predict dogs.
      </p>
      <div class="image-holder">
        <img src="img/only-cats.png" width="600" />
        <p>
          If we only use images of cats during training, the model will 'cheat'.
          It will learn to ignore all of the input features -- no matter what
          you put in, it will predict cat.
        </p>
      </div>
      <p>
        So let's just include some dogs in our training set, right? It's not
        that easy. If we accidentally have correlations in our data that let the
        model minimize the loss, the model will use it.
      </p>
      <div class="image-holder">
        <img src="img/colorswitch.png" width="600" />
        <p>
          If we only train on white cats and black dogs, the model isn't going
          to learn anything about cats and dogs. It's only going to learn about
          color. If the model sees a black cat, it will predict 'dog'. And if it
          sees a white dog, it'll predict 'cat'.
        </p>
      </div>
      <p>
        This is why we have to care about the input features. Data matters,
        whether we're training a pet identifier or a
        <a href="https://www.jefftk.com/p/detecting-tanks">tank detector</a>.
        The more training data we have, the better the input will match the true
        data distributions, and the better our model will perform.
      </p>
      <p>
        Ok so we just get enough data and that solves the problem, right? I work
        at Google, which arguably has the most data access in the world, and let
        me tell you it's not that simple. Getting access to more data is
        <i>hard</i>. At a large enough scale, it's inefficient.
      </p>
      <h6>So how do we change loss functions?</h6>
      <p>
        It's hard to figure out exactly how changing the loss will impact the
        model -- I mean, we can calculate the outcomes with math but
        realistically that does not provide us with a great understanding of how
        the model will respond. As a result, changing the losses of a model is
        pretty volatile.
      </p>
      <p>
        To a first approximation, we can tune our model by thinking about how
        the data is correlated with the outcomes we want, and adding losses that
        emphasize that data.
      </p>

      <p>
        What helped this all click for me was thinking about imbalanced label
        distributions.
      </p>
    </div>
  </div>
  <div class="footer"></div>
</div>
