<title>Simple DL Part 2: Embeddings</title>
<meta name="viewport" content="width=800" />

<meta name="description" content="Building intuition about deep learning." />
<meta property="og:title" content="SimpleDL pt 2: Embeddings" />
<meta property="og:type" content="website" />
<meta
  property="og:description"
  content="Building intuition about deep learning."
/>
<meta
  property="og:image"
  content="https://amolkapoor.com/writing/img/networkeffects.jpg"
/>
<meta name="twitter:title" content="SimpleDL pt 2: Embeddings" />
<meta
  name="twitter:description"
  content="Building intuition about deep learning."
/>
<meta
  name="twitter:image"
  content="https://amolkapoor.com/writing/img/networkeffects.jpg"
/>
<meta name="twitter:card" content="summary_large_image" />

<link rel="icon" href="spy.ico" type="image/x-icon" />
<link rel="shortcut icon" href="spy.ico" type="image/x-icon" />
<link rel="stylesheet" href="theme.css" />

<style></style>
<!-- Google Analytics -->
<script
  async
  src="https://www.googletagmanager.com/gtag/js?id=UA-131666667-1"
></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() {
    dataLayer.push(arguments);
  }
  gtag('js', new Date());

  gtag('config', 'UA-131666667-1');
</script>

<div class="header">
  <h1>Writing</h1>
  <h3>Amol Kapoor</h3>
  <a href="./index.html">Back to table of contents.</a>
</div>

<div class="content">
  <div class="writing-holder">
    <h4>Simple DL Part 2: Embeddings</h4>
    <h6>December, 2020</h6>

    <div class="writing">
      <p>
        In my opinion, you need to understand embeddings to really 'get' deep
        learning. Embeddings are the magic fairy dust that power every deep
        learning model, from ImageNet to GPT-3. I think in embeddings.
        Embeddings are the foundation for any intuition I have about DL, so all
        of my future posts in this series are going to refer back to the
        embedding concept.
      </p>
      <p>
        Because this is important foundation, I'll be splitting this section
        into two parts. The
        <a href="./simpledl_2a.html">first section</a> tries to define
        embeddings, while the
        <a href="./simpledl_2b.html">second part</a> explains why they work.
      </p>

      <h6>TLDR</h6>
      <ul>
        <li>
          Embeddings are stores of information represented as a list of floats
          (a float vector).
        </li>
        <li>
          Float-vectors are unique because they are continuous, which means we
          can think of them like points on a map (or, more generally, points on
          an N-dimensional surface).
        </li>
        <li>
          A good embedding is one where similar information is 'close' to each
          other in our map.
        </li>
        <li>
          Because embeddings are lists of floats that represent concepts, we
          can turn concepts into computation.
        </li>
        <li>
          A deep learning model is made of a stack of embeddings. Embeddings
          are constrained by the input data (features) and the loss function.
        </li>
        <li>
          The features limit what the embeddings can learn, and the loss tells
          the model what to prioritize. Models are as good as their features
          and as bad as their loss.
        </li>
        <li>
          We can improve a model's performance by changing the features, the
          architecture, or the loss function. These change the embeddings,
          which changes the underlying information map.
        </li>
      </ul>
    </div>
  </div>
  <div class="footer">
    <a href="./index.html">Back to Writing</a>
  </div>
</div>
